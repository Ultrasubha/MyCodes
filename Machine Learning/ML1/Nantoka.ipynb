{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "iris = datasets.load_iris()\n",
    "X,y = iris.data[50:,[1,2]], iris.target[50:]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "ROC AUC: 0.92 (+/- 0.15) [Logistic regression]\n",
      "ROC AUC: 0.87 (+/- 0.18) [Decision tree]\n",
      "ROC AUC: 0.85 (+/- 0.13) [KNN]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "clf1 = LogisticRegression(penalty='l2', C=0.001, solver='lbfgs', random_state=1)\n",
    "clf2 = DecisionTreeClassifier(max_depth=1, criterion='entropy', random_state=0)\n",
    "clf3 = KNeighborsClassifier(n_neighbors=1, p=2, metric='minkowski')\n",
    "pipe1 = Pipeline([['sc', StandardScaler()], ['clf', clf1]])\n",
    "pipe3 = Pipeline([['sc', StandardScaler()], ['clf', clf3]])\n",
    "clf_labels = ['Logistic regression', 'Decision tree', 'KNN']\n",
    "print('10-fold cross validation:\\n')\n",
    "for clf, label in zip([pipe1, clf2, pipe3], clf_labels):\n",
    "    scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=10, scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MajorityVoteClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\_WorkSpace\\MyCodes\\Machine Learning\\ML1\\Nantoka.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/_WorkSpace/MyCodes/Machine%20Learning/ML1/Nantoka.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m VotingClassifier\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/_WorkSpace/MyCodes/Machine%20Learning/ML1/Nantoka.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mv_clf \u001b[39m=\u001b[39m MajorityVoteClassifier(classifiers\u001b[39m=\u001b[39m[pipe1, clf2, pipe3])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/_WorkSpace/MyCodes/Machine%20Learning/ML1/Nantoka.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m clf_labels \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mMajority voting\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/_WorkSpace/MyCodes/Machine%20Learning/ML1/Nantoka.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m all_clf \u001b[39m=\u001b[39m [pipe1, clf2, pipe3, mv_clf]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MajorityVoteClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "mv_clf = MajorityVoteClassifier(classifiers=[pipe1, clf2, pipe3])\n",
    "clf_labels += ['Majority voting']\n",
    "all_clf = [pipe1, clf2, pipe3, mv_clf]\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=10, scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression Matrix -</h3>\n",
    "R square score is a statistical measure that represents the goodness of the fit of the regression model. \n",
    "R 2 = 1 − sum squared regression (SSR) total sum of squares (SST) , = 1 − ∑ ( y i − y i ^ ) 2 ∑ ( y i − y ¯ ) 2\n",
    "In the formula, R**2 is a comparison of sum of squared Errors by Total sum of squares.\n",
    "if R**2 close to 1, It is a very highly accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# r2_score(ytest, ypred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Mean Squared Error</h3>\n",
    "Mean Squared Error is Machine Learning is defined as the mean/average of the squared differences between the actual and the estimated values.<br>\n",
    "If Mean Squared Error is 0 it means that there is no Error.\n",
    "If Mean Squared Error value increases that means the model error will be increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# mean_squared_error(ytest, ypred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Mean absolute error</h3>\n",
    "Mean absolute error it is a mean of the mistakes in the collected prediction. In this error, the absolute difference between the Actual or True values and the values that are predicted.\n",
    "MAE = (sum from i=1 to n of |y_i - x_i|) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Mean squared logarithmic Error</h3>\n",
    "It computes the mean squared logarithmic Error between the true value or the actual value and the target value.\n",
    "MSLE takes a similar approach as the mean squared Error but it uses the logarithmic to offset the large outliers in a dataset that it will remove the outliers and treat them as they were on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "# mean_squared_log_error(ytest,ypred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Mean absolute percentage error </h3>\n",
    "It is calculated by considering the difference between the Actual value and the predicted value and dividing it by the actual value.\n",
    "Formula check from Google"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Explained variance scores</h3>\n",
    "It explains the dispersion of errors of a given dataset.\n",
    "Below 1 the models performace degrade.\n",
    "[Insert formula]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\_WorkSpace\\MyCodes\\Machine Learning\\ML1\\Nantoka.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/_WorkSpace/MyCodes/Machine%20Learning/ML1/Nantoka.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m RANSACRegressor\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/_WorkSpace/MyCodes/Machine%20Learning/ML1/Nantoka.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m r2 \u001b[39m=\u001b[39m r2_score(y_test, y_test_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/_WorkSpace/MyCodes/Machine%20Learning/ML1/Nantoka.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mR2-Squared Error: \u001b[39m\u001b[39m\"\u001b[39m, r2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print(\"R2-Squared Error: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\_WorkSpace\\MyCodes\\Machine Learning\\ML1\\Nantoka.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/_WorkSpace/MyCodes/Machine%20Learning/ML1/Nantoka.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mse\u001b[39m=\u001b[39m mean_squared_error(y_test,y_test_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/_WorkSpace/MyCodes/Machine%20Learning/ML1/Nantoka.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMean squared error\u001b[39m\u001b[39m\"\u001b[39m, mse)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "mse= mean_squared_error(y_test,y_test_pred)\n",
    "print(\"Mean squared error\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
